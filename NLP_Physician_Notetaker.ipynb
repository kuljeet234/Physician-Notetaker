{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW_7KcQYtDlQ",
        "outputId": "ff2a5ca1-4f98-4d16-e66b-dd346ae4a169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.19.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers torch spacy scikit-learn pandas numpy accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydi7e6ANt5mO",
        "outputId": "0debe051-10a7-4be1-9f6b-508cb8683e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "\u001b[38;5;1m✘ No compatible package found for 'en_ner_bc5cdr_md' (spaCy v3.8.7)\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system('python -m spacy download en_core_web_sm')\n",
        "get_ipython().system('python -m spacy download en_ner_bc5cdr_md  # Biomedical NER model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IN4xG2it8nc",
        "outputId": "968c69be-c33b-4c48-d46b-88784f7b6a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INITIALIZING CLINICAL PIPELINE\n",
            "Loading models...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Models loaded\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROCESSING TRANSCRIPT\n",
            "\n",
            "Extracting medical entities...\n",
            "Analyzing sentiment...\n",
            "Generating SOAP note...\n",
            "\n",
            "✓ PROCESSING COMPLETE\n",
            "\n",
            " MEDICAL SUMMARY:\n",
            "{\n",
            "  \"Patient_Name\": \"Jones\",\n",
            "  \"Symptoms\": [\n",
            "    \"Back Pain\",\n",
            "    \"Backache\",\n",
            "    \"Neck Pain\",\n",
            "    \"Stiffness\"\n",
            "  ],\n",
            "  \"Diagnosis\": \"whiplash injury\",\n",
            "  \"Treatment\": [\n",
            "    \"Painkiller\",\n",
            "    \"Painkillers\"\n",
            "  ],\n",
            "  \"Current_Status\": \"Under observation\",\n",
            "  \"Prognosis\": \"within six months\",\n",
            "  \"Confidence_Score\": 0.9\n",
            "}\n",
            "\n",
            " SENTIMENT ANALYSIS:\n",
            "{\n",
            "  \"Sentiment\": \"Anxious\",\n",
            "  \"Intent\": \"Reporting Symptoms\",\n",
            "  \"Confidence\": 0.9131569862365723\n",
            "}\n",
            "\n",
            " SOAP NOTE:\n",
            "{\n",
            "  \"Subjective\": {\n",
            "    \"Chief_Complaint\": \"Good morning, doctor. I'm doing better, but I still have some discomfort now and then.\",\n",
            "    \"History_of_Present_Illness\": \"Good morning, doctor. I'm doing better, but I still have some discomfort now and then. Yes, it was on September 1st, around 12:30 in the afternoon. I was driving from Cheadle Hulme to Manchester when I had to stop in traffic. Out of nowhere, another car hit me from behind, which pushed my car into the one in front. Yes, I always do. At first, I was just shocked. But then I realized I had hit my head on the steering wheel, and I could feel pain in my neck and back almost right away. Yes, I went t\"\n",
            "  },\n",
            "  \"Objective\": {\n",
            "    \"Physical_Exam\": \"Everything looks good. Your neck and back have a full range of movement, and there's no tenderness or signs of lasting damage. Your muscles and spine seem to be in good condition\",\n",
            "    \"Observations\": \"Patient appears stable\"\n",
            "  },\n",
            "  \"Assessment\": {\n",
            "    \"Diagnosis\": \"whiplash injury\",\n",
            "    \"Severity\": \"Mild, improving\"\n",
            "  },\n",
            "  \"Plan\": {\n",
            "    \"Treatment_Plan\": \"Continue current management\",\n",
            "    \"Follow-Up\": \"Follow-up appointment to be scheduled\"\n",
            "  }\n",
            "}\n",
            "✓ COMPLETE\n",
            "✅ Results saved to clinical_results.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, List, Tuple, Set\n",
        "from dataclasses import dataclass, asdict\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import spacy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MedicalSummary:\n",
        "    Patient_Name: str\n",
        "    Symptoms: List[str]\n",
        "    Diagnosis: str\n",
        "    Treatment: List[str]\n",
        "    Current_Status: str\n",
        "    Prognosis: str\n",
        "    Confidence_Score: float\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SentimentResult:\n",
        "    Sentiment: str\n",
        "    Intent: str\n",
        "    Confidence: float\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SOAPNote:\n",
        "    Subjective: Dict[str, str]\n",
        "    Objective: Dict[str, str]\n",
        "    Assessment: Dict[str, str]\n",
        "    Plan: Dict[str, str]\n",
        "\n",
        "\n",
        "class MedicalEntityValidator:\n",
        "    def __init__(self, sentence_model):\n",
        "        self.sentence_model = sentence_model\n",
        "\n",
        "        self.valid_examples = {\n",
        "            'symptom': [\n",
        "                \"neck pain\", \"back pain\", \"headache\", \"nausea\", \"dizziness\", \"fatigue\",\n",
        "                \"chest pain\", \"weakness\", \"numbness\", \"tingling\", \"swelling\", \"stiffness\",\n",
        "                \"fever\", \"cough\", \"sore throat\", \"abdominal pain\", \"joint pain\", \"muscle aches\",\n",
        "                \"blurred vision\", \"loss of appetite\", \"weight loss\", \"difficulty breathing\",\n",
        "                \"palpitations\", \"confusion\", \"increased thirst\", \"frequent urination\",\n",
        "                \"discomfort\", \"ache\", \"soreness\", \"tenderness\", \"bruising\", \"rash\"\n",
        "            ],\n",
        "            'diagnosis': [\n",
        "                \"whiplash injury\", \"diabetes\", \"hypertension\", \"pneumonia\", \"fracture\",\n",
        "                \"sprain\", \"strain\", \"arthritis\", \"bronchitis\", \"asthma\", \"heart disease\",\n",
        "                \"stroke\", \"infection\", \"inflammation\", \"herniated disc\", \"concussion\",\n",
        "                \"type 2 diabetes\", \"migraine\", \"gastritis\", \"contusion\", \"laceration\"\n",
        "            ],\n",
        "            'treatment': [\n",
        "                \"physiotherapy\", \"physical therapy\", \"surgery\", \"rehabilitation\",\n",
        "                \"exercise program\", \"massage therapy\", \"rest\", \"ice therapy\", \"heat therapy\",\n",
        "                \"occupational therapy\", \"dietary modifications\", \"lifestyle changes\",\n",
        "                \"blood sugar monitoring\", \"insulin therapy\", \"medication management\",\n",
        "                \"pain management\", \"wound care\", \"immobilization\", \"compression therapy\"\n",
        "            ],\n",
        "            'medication': [\n",
        "                \"ibuprofen\", \"aspirin\", \"acetaminophen\", \"painkiller\", \"antibiotic\",\n",
        "                \"metformin\", \"insulin\", \"anti-inflammatory\", \"analgesic\", \"steroid\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        self.valid_embeddings = {}\n",
        "        for entity_type, examples in self.valid_examples.items():\n",
        "            embeddings = sentence_model.encode(examples)\n",
        "            self.valid_embeddings[entity_type] = embeddings\n",
        "\n",
        "        self.forbidden_phrases = [\n",
        "            'these symptoms', 'your symptoms', 'those symptoms', 'the symptoms',\n",
        "            'this symptom', 'that symptom', 'my symptoms', 'any symptoms',\n",
        "            'such symptoms', 'similar symptoms', 'following symptoms',\n",
        "            'some discomfort', 'any discomfort', 'the discomfort',\n",
        "            'any pain', 'the pain', 'some pain', 'this pain', 'that pain',\n",
        "            'any lingering pain', 'lingering pain', 'the stiffness', 'some stiffness',\n",
        "            'pain now', 'occasional backaches', 'occasional backache',\n",
        "            'experiencing pain', 'feel pain', 'take pain', 'felt pain',\n",
        "            'what', 'when', 'where', 'why', 'how', 'which', 'who',\n",
        "            'feeling', 'noticed', 'started', 'stopped', 'began',\n",
        "            'help with the', 'to help', 'physiotherapy to'\n",
        "        ]\n",
        "\n",
        "        self.single_word_forbidden = [\n",
        "            'pain', 'discomfort', 'stiffness', 'ache', 'neck', 'back',\n",
        "            'head', 'help', 'with', 'the', 'experiencing', 'feel', 'take'\n",
        "        ]\n",
        "\n",
        "    def is_valid_entity(self, text: str, entity_type: str) -> Tuple[bool, float]:\n",
        "        text_lower = text.lower().strip()\n",
        "\n",
        "        if len(text_lower) < 3 or len(text_lower) > 60:\n",
        "            return False, 0.0\n",
        "\n",
        "        if text_lower in self.forbidden_phrases:\n",
        "            return False, 0.0\n",
        "\n",
        "        for forbidden in ['to help with', 'help with the', 'occasional']:\n",
        "            if forbidden in text_lower:\n",
        "                return False, 0.0\n",
        "\n",
        "        words = text_lower.split()\n",
        "        if len(words) == 1 and text_lower in self.single_word_forbidden:\n",
        "            return False, 0.0\n",
        "\n",
        "        if words[0] in ['what', 'when', 'where', 'why', 'how', 'which', 'who', 'whom', 'occasional']:\n",
        "            return False, 0.0\n",
        "\n",
        "        filler_words = {'the', 'a', 'an', 'this', 'that', 'these', 'those', 'my', 'your', 'his', 'her', 'their', 'some', 'any'}\n",
        "        content_words = [w for w in words if w not in filler_words]\n",
        "        if len(content_words) == 0:\n",
        "            return False, 0.0\n",
        "\n",
        "        if entity_type == 'symptom':\n",
        "            if len(words) <= 2 and not any(kw in text_lower for kw in ['pain', 'ache', 'discomfort', 'soreness', 'weakness', 'numbness', 'tingling', 'swelling', 'stiffness', 'backache', 'headache']):\n",
        "                return False, 0.0\n",
        "\n",
        "        if entity_type in self.valid_embeddings:\n",
        "            text_embedding = self.sentence_model.encode([text_lower])[0]\n",
        "            similarities = cosine_similarity(\n",
        "                text_embedding.reshape(1, -1),\n",
        "                self.valid_embeddings[entity_type]\n",
        "            )[0]\n",
        "            max_similarity = float(np.max(similarities))\n",
        "\n",
        "            thresholds = {\n",
        "                'symptom': 0.58,\n",
        "                'diagnosis': 0.60,\n",
        "                'treatment': 0.55,\n",
        "                'medication': 0.65\n",
        "            }\n",
        "\n",
        "            threshold = thresholds.get(entity_type, 0.60)\n",
        "\n",
        "            if max_similarity < threshold:\n",
        "                return False, max_similarity\n",
        "\n",
        "            return True, max_similarity\n",
        "\n",
        "        return True, 0.5\n",
        "\n",
        "\n",
        "class EnhancedClinicalExtractor:\n",
        "    def __init__(self, use_gpu: bool = True):\n",
        "        self.device = 0 if use_gpu and torch.cuda.is_available() else -1\n",
        "\n",
        "        print(\"Loading models...\")\n",
        "\n",
        "        try:\n",
        "            self.medical_ner = pipeline(\n",
        "                \"ner\",\n",
        "                model=\"alvaroalon2/biobert_diseases_ner\",\n",
        "                aggregation_strategy=\"max\",\n",
        "                device=self.device\n",
        "            )\n",
        "        except:\n",
        "            self.medical_ner = pipeline(\n",
        "                \"ner\",\n",
        "                model=\"d4data/biomedical-ner-all\",\n",
        "                aggregation_strategy=\"max\",\n",
        "                device=self.device\n",
        "            )\n",
        "\n",
        "        self.sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "        self.qa_pipeline = pipeline(\n",
        "            \"question-answering\",\n",
        "            model=\"deepset/roberta-base-squad2\",\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        self.zero_shot = pipeline(\n",
        "            \"zero-shot-classification\",\n",
        "            model=\"facebook/bart-large-mnli\",\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
        "        except:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "        self.validator = MedicalEntityValidator(self.sentence_model)\n",
        "        print(\"✓ Models loaded\\n\")\n",
        "\n",
        "    def extract_symptoms_robust(self, text: str) -> Set[str]:\n",
        "        symptoms = set()\n",
        "        doc = self.nlp(text)\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        symptom_patterns = [\n",
        "            r'([a-z]+)\\s+and\\s+([a-z]+)\\s+pain',\n",
        "            r'([a-z]+)\\s+pain',\n",
        "            r'pain\\s+in\\s+(?:my|the)\\s+([a-z]+)',\n",
        "            r'my\\s+([a-z]+)\\s+(?:hurts?|aches?)',\n",
        "        ]\n",
        "\n",
        "        for pattern in symptom_patterns:\n",
        "            matches = re.finditer(pattern, text_lower)\n",
        "            for match in matches:\n",
        "                symptoms_found = []\n",
        "\n",
        "                if 'and' in pattern:\n",
        "                    body_part1 = match.group(1).strip()\n",
        "                    body_part2 = match.group(2).strip()\n",
        "                    symptoms_found.append(f\"{body_part1} pain\")\n",
        "                    symptoms_found.append(f\"{body_part2} pain\")\n",
        "                else:\n",
        "                    body_part = match.group(1).strip()\n",
        "                    symptoms_found.append(f\"{body_part} pain\")\n",
        "\n",
        "                for symptom in symptoms_found:\n",
        "                    if len(symptom) < 8:\n",
        "                        continue\n",
        "\n",
        "                    is_valid, conf = self.validator.is_valid_entity(symptom, 'symptom')\n",
        "                    if is_valid and conf > 0.52:\n",
        "                        symptom_clean = ' '.join(word.capitalize() for word in symptom.split())\n",
        "                        symptoms.add(symptom_clean)\n",
        "\n",
        "        specific_symptoms = [\n",
        "            'headache', 'backache', 'nausea', 'dizziness', 'fatigue',\n",
        "            'numbness', 'tingling', 'weakness', 'swelling', 'stiffness'\n",
        "        ]\n",
        "\n",
        "        for specific in specific_symptoms:\n",
        "            if specific in text_lower:\n",
        "                symptoms.add(specific.capitalize())\n",
        "\n",
        "        return symptoms\n",
        "\n",
        "    def extract_treatments_robust(self, text: str) -> Set[str]:\n",
        "        treatments = set()\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        sessions_pattern = r'(\\d+)\\s+sessions?\\s+of\\s+([a-z]+)'\n",
        "        matches = re.finditer(sessions_pattern, text_lower)\n",
        "        for match in matches:\n",
        "            treatment = match.group(2).strip()\n",
        "            if len(treatment) >= 5:\n",
        "                is_valid, conf = self.validator.is_valid_entity(treatment, 'treatment')\n",
        "                if is_valid and conf > 0.50:\n",
        "                    treatments.add(treatment.capitalize())\n",
        "\n",
        "        medication_keywords = ['painkiller', 'painkillers', 'medication', 'metformin', 'insulin']\n",
        "        for med in medication_keywords:\n",
        "            if med in text_lower:\n",
        "                treatments.add(med.capitalize() if not med.endswith('s') else med.capitalize())\n",
        "\n",
        "        therapy_pattern = r'([a-z]{8,})\\s+(?:therapy|treatment)'\n",
        "        matches = re.finditer(therapy_pattern, text_lower)\n",
        "        for match in matches:\n",
        "            therapy = match.group(1).strip()\n",
        "            if len(therapy) >= 8:\n",
        "                is_valid, conf = self.validator.is_valid_entity(therapy, 'treatment')\n",
        "                if is_valid and conf > 0.50:\n",
        "                    treatments.add(therapy.capitalize())\n",
        "\n",
        "        drug_pattern = r'\\b([A-Z][a-z]{4,}(?:in|ol|ate|ide|ine))\\b'\n",
        "        matches = re.finditer(drug_pattern, text)\n",
        "        for match in matches:\n",
        "            med = match.group(1).strip()\n",
        "            if len(med) >= 6:\n",
        "                is_valid, conf = self.validator.is_valid_entity(med, 'medication')\n",
        "                if is_valid and conf > 0.60:\n",
        "                    treatments.add(med)\n",
        "\n",
        "        return treatments\n",
        "\n",
        "    def extract_using_qa(self, text: str) -> Dict[str, str]:\n",
        "        questions = {\n",
        "            'diagnosis': \"What medical condition, disease, or injury was diagnosed?\",\n",
        "            'current_status': \"What is the patient's current condition or how are they feeling now?\",\n",
        "            'prognosis': \"What is the expected recovery time or outcome?\"\n",
        "        }\n",
        "\n",
        "        extracted = {}\n",
        "\n",
        "        for key, question in questions.items():\n",
        "            try:\n",
        "                result = self.qa_pipeline(\n",
        "                    question=question,\n",
        "                    context=text,\n",
        "                    max_answer_len=100\n",
        "                )\n",
        "\n",
        "                if result['score'] > 0.30:\n",
        "                    answer = result['answer'].strip()\n",
        "                    answer = re.sub(r'^(a|an|the)\\s+', '', answer, flags=re.IGNORECASE)\n",
        "                    if len(answer) > 5:\n",
        "                        extracted[key] = answer\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return extracted\n",
        "\n",
        "    def generate_summary(self, transcript: str) -> MedicalSummary:\n",
        "        print(\"Extracting medical entities...\")\n",
        "\n",
        "        qa_results = self.extract_using_qa(transcript)\n",
        "        symptoms = self.extract_symptoms_robust(transcript)\n",
        "        treatments = self.extract_treatments_robust(transcript)\n",
        "\n",
        "        doc = self.nlp(transcript)\n",
        "        patient_name = \"Unknown\"\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == 'PERSON':\n",
        "                name = ent.text.replace('Mr.', '').replace('Ms.', '').replace('Mrs.', '').replace('Dr.', '').strip()\n",
        "                if name and len(name) > 2 and name.lower() not in ['doctor', 'physician']:\n",
        "                    patient_name = name\n",
        "                    break\n",
        "\n",
        "        diagnosis = qa_results.get('diagnosis', '')\n",
        "        if not diagnosis or len(diagnosis) < 5:\n",
        "            diagnosis_patterns = [\n",
        "                r'(?:diagnosed with|said it was|looks like)\\s+(?:a |an |you (?:may )?have (?:a |an )?)?([a-zA-Z\\s]{5,40}?)(?:\\.|,|;|\\?)',\n",
        "            ]\n",
        "            for pattern in diagnosis_patterns:\n",
        "                match = re.search(pattern, transcript, re.IGNORECASE)\n",
        "                if match:\n",
        "                    diagnosis = match.group(1).strip().title()\n",
        "                    break\n",
        "\n",
        "        if not diagnosis or len(diagnosis) < 5:\n",
        "            diagnosis = \"To be determined\"\n",
        "\n",
        "        current_status = qa_results.get('current_status', 'Under observation')\n",
        "        if len(current_status) > 120:\n",
        "            current_status = current_status[:117] + \"...\"\n",
        "\n",
        "        prognosis = qa_results.get('prognosis', 'Prognosis to be determined')\n",
        "        if len(prognosis) > 150:\n",
        "            prognosis = prognosis[:147] + \"...\"\n",
        "\n",
        "        has_symptoms = len(symptoms) > 0\n",
        "        has_diagnosis = diagnosis != \"To be determined\"\n",
        "        has_treatment = len(treatments) > 0\n",
        "\n",
        "        confidence = 0.50\n",
        "        if has_diagnosis and has_symptoms:\n",
        "            confidence += 0.25\n",
        "        elif has_diagnosis or has_symptoms:\n",
        "            confidence += 0.15\n",
        "        if has_treatment:\n",
        "            confidence += 0.10\n",
        "        if len(qa_results) >= 2:\n",
        "            confidence += 0.05\n",
        "\n",
        "        confidence = max(0.50, min(0.90, confidence))\n",
        "\n",
        "        return MedicalSummary(\n",
        "            Patient_Name=patient_name,\n",
        "            Symptoms=sorted(list(symptoms)) if symptoms else [\"Not specified\"],\n",
        "            Diagnosis=diagnosis,\n",
        "            Treatment=sorted(list(treatments)) if treatments else [\"Not specified\"],\n",
        "            Current_Status=current_status,\n",
        "            Prognosis=prognosis,\n",
        "            Confidence_Score=float(confidence)\n",
        "        )\n",
        "\n",
        "\n",
        "class ClinicalSentimentAnalyzer:\n",
        "    def __init__(self, use_gpu: bool = True):\n",
        "        self.device = 0 if use_gpu and torch.cuda.is_available() else -1\n",
        "\n",
        "        self.zero_shot = pipeline(\n",
        "            \"zero-shot-classification\",\n",
        "            model=\"facebook/bart-large-mnli\",\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "    def analyze(self, text: str) -> SentimentResult:\n",
        "        if not text or len(text) < 10:\n",
        "            return SentimentResult(Sentiment=\"Neutral\", Intent=\"General conversation\", Confidence=0.5)\n",
        "\n",
        "        sentiment_result = self.zero_shot(\n",
        "            text[:512],\n",
        "            candidate_labels=[\"patient is anxious or worried\", \"patient is reassured and calm\", \"patient is neutral\"],\n",
        "            hypothesis_template=\"{}.\"\n",
        "        )\n",
        "\n",
        "        sentiment_map = {\n",
        "            \"patient is anxious or worried\": \"Anxious\",\n",
        "            \"patient is reassured and calm\": \"Reassured\",\n",
        "            \"patient is neutral\": \"Neutral\"\n",
        "        }\n",
        "\n",
        "        sentiment = sentiment_map.get(sentiment_result['labels'][0], \"Neutral\")\n",
        "        confidence = float(sentiment_result['scores'][0])\n",
        "\n",
        "        intent_result = self.zero_shot(\n",
        "            text[:512],\n",
        "            candidate_labels=[\"seeking reassurance\", \"reporting symptoms\", \"seeking information\", \"expressing gratitude\", \"describing medical history\"],\n",
        "            hypothesis_template=\"The patient is {}.\"\n",
        "        )\n",
        "\n",
        "        intent = intent_result['labels'][0].title()\n",
        "\n",
        "        return SentimentResult(\n",
        "            Sentiment=sentiment,\n",
        "            Intent=intent,\n",
        "            Confidence=confidence\n",
        "        )\n",
        "\n",
        "\n",
        "class SOAPNoteGenerator:\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        self.qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "    def generate(self, transcript: str) -> SOAPNote:\n",
        "        print(\"Generating SOAP note...\")\n",
        "\n",
        "        subjective_cc = self._qa_extract(transcript, \"What is the patient's main complaint?\")\n",
        "        if not subjective_cc or len(subjective_cc) < 5:\n",
        "            lines = transcript.split('\\n')\n",
        "            for line in lines:\n",
        "                if 'patient:' in line.lower():\n",
        "                    statement = line.split(':', 1)[1].strip()\n",
        "                    if len(statement) > 10 and not statement.endswith('?'):\n",
        "                        subjective_cc = statement[:150]\n",
        "                        break\n",
        "\n",
        "        subjective_hpi = self._extract_patient_statements(transcript)\n",
        "\n",
        "        objective_exam = self._qa_extract(transcript, \"What were the physical examination findings?\")\n",
        "        if not objective_exam or len(objective_exam) < 10:\n",
        "            objective_exam = \"Not documented\"\n",
        "\n",
        "        objective_obs = self._qa_extract(transcript, \"What observations were made about the patient?\")\n",
        "        if not objective_obs or len(objective_obs) < 5:\n",
        "            objective_obs = \"Patient appears stable\"\n",
        "\n",
        "        assessment_dx = self._qa_extract(transcript, \"What was the diagnosis?\")\n",
        "        if not assessment_dx or len(assessment_dx) < 5:\n",
        "            patterns = [\n",
        "                r'(?:diagnosed with|said it was)\\s+(?:a |an )?([a-zA-Z\\s]{5,40}?)(?:\\.|,)'\n",
        "            ]\n",
        "            for pattern in patterns:\n",
        "                match = re.search(pattern, transcript, re.IGNORECASE)\n",
        "                if match:\n",
        "                    assessment_dx = match.group(1).strip().title()\n",
        "                    break\n",
        "        if not assessment_dx or len(assessment_dx) < 5:\n",
        "            assessment_dx = \"To be determined\"\n",
        "\n",
        "        assessment_severity = self._determine_severity(transcript)\n",
        "\n",
        "        plan_tx = self._extract_treatment_plan(transcript)\n",
        "        plan_followup = self._extract_followup(transcript)\n",
        "\n",
        "        return SOAPNote(\n",
        "            Subjective={\n",
        "                \"Chief_Complaint\": subjective_cc if subjective_cc else \"Not specified\",\n",
        "                \"History_of_Present_Illness\": subjective_hpi[:500] if subjective_hpi else \"Not documented\"\n",
        "            },\n",
        "            Objective={\n",
        "                \"Physical_Exam\": objective_exam,\n",
        "                \"Observations\": objective_obs\n",
        "            },\n",
        "            Assessment={\n",
        "                \"Diagnosis\": assessment_dx,\n",
        "                \"Severity\": assessment_severity\n",
        "            },\n",
        "            Plan={\n",
        "                \"Treatment_Plan\": plan_tx if plan_tx else \"Continue current management\",\n",
        "                \"Follow-Up\": plan_followup if plan_followup else \"Return as needed (PRN)\"\n",
        "            }\n",
        "        )\n",
        "\n",
        "    def _qa_extract(self, text: str, question: str) -> str:\n",
        "        try:\n",
        "            result = self.qa(question=question, context=text, max_answer_len=100)\n",
        "            if result['score'] > 0.25:\n",
        "                return result['answer'].strip()\n",
        "        except:\n",
        "            pass\n",
        "        return \"\"\n",
        "\n",
        "    def _extract_patient_statements(self, transcript: str) -> str:\n",
        "        lines = transcript.split('\\n')\n",
        "        statements = []\n",
        "\n",
        "        for line in lines:\n",
        "            if 'patient:' in line.lower():\n",
        "                content = line.split(':', 1)[1].strip()\n",
        "                if content and len(content) > 10:\n",
        "                    statements.append(content)\n",
        "\n",
        "        return \" \".join(statements[:5])\n",
        "\n",
        "    def _extract_treatment_plan(self, transcript: str) -> str:\n",
        "        sentences = [sent.text for sent in self.nlp(transcript).sents]\n",
        "        treatment_sentences = []\n",
        "\n",
        "        treatment_keywords = ['prescribe', 'recommend', 'start', 'continue', 'medication', 'therapy', 'treatment', 'sessions']\n",
        "        patient_keywords = ['had to', 'went through', 'have to', 'will have', 'need to']\n",
        "\n",
        "        for sent in sentences:\n",
        "            sent_lower = sent.lower()\n",
        "\n",
        "            if 'physician:' in sent_lower or 'doctor:' in sent_lower:\n",
        "                if any(kw in sent_lower for kw in treatment_keywords):\n",
        "                    if not sent.strip().endswith('?'):\n",
        "                        treatment_sentences.append(sent.strip())\n",
        "            elif any(kw in sent_lower for kw in patient_keywords):\n",
        "                if any(tx in sent_lower for tx in ['physiotherapy', 'therapy', 'medication', 'sessions']):\n",
        "                    continue\n",
        "\n",
        "        if treatment_sentences:\n",
        "            return ' '.join(treatment_sentences[:2])[:300]\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def _extract_followup(self, transcript: str) -> str:\n",
        "        followup_patterns = [\n",
        "            r'(?:schedule|come back|return)\\s+(?:for\\s+)?(?:a\\s+)?follow[- ]?up\\s+([^.]{5,80})',\n",
        "            r'follow[- ]?up\\s+(?:in|after|next)\\s+([^.]{5,50})',\n",
        "        ]\n",
        "\n",
        "        for pattern in followup_patterns:\n",
        "            match = re.search(pattern, transcript, re.IGNORECASE)\n",
        "            if match:\n",
        "                followup = match.group(1).strip() if match.lastindex >= 1 else match.group(0).strip()\n",
        "                followup = re.sub(r'\\s+', ' ', followup)\n",
        "                if 10 < len(followup) < 100:\n",
        "                    return followup.capitalize()\n",
        "\n",
        "        if 'follow up' in transcript.lower() or 'follow-up' in transcript.lower():\n",
        "            return \"Follow-up appointment to be scheduled\"\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def _determine_severity(self, text: str) -> str:\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        if any(word in text_lower for word in ['severe', 'critical', 'acute']):\n",
        "            return \"Severe\"\n",
        "        elif any(word in text_lower for word in ['improving', 'better', 'recovery']):\n",
        "            return \"Mild, improving\"\n",
        "        elif any(word in text_lower for word in ['mild', 'minor']):\n",
        "            return \"Mild\"\n",
        "        else:\n",
        "            return \"Moderate\"\n",
        "\n",
        "\n",
        "class ClinicalTranscriptionPipeline:\n",
        "    def __init__(self, use_gpu: bool = True):\n",
        "\n",
        "        print(\"INITIALIZING CLINICAL PIPELINE\")\n",
        "\n",
        "\n",
        "        self.extractor = EnhancedClinicalExtractor(use_gpu=use_gpu)\n",
        "        self.sentiment_analyzer = ClinicalSentimentAnalyzer(use_gpu=use_gpu)\n",
        "        self.soap_generator = SOAPNoteGenerator()\n",
        "\n",
        "    def save_results(self, results, filename=\"results.json\"):\n",
        "        # Get the current directory where the script is running\n",
        "        current_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "        save_path = os.path.join(current_dir, filename)\n",
        "\n",
        "        # Save JSON results\n",
        "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\nResults saved successfully at: {save_path}\")\n",
        "\n",
        "    def process_transcript(self, transcript: str, patient_text: str = None) -> Dict:\n",
        "        print(\"PROCESSING TRANSCRIPT\\n\")\n",
        "\n",
        "        summary = self.extractor.generate_summary(transcript)\n",
        "\n",
        "        print(\"Analyzing sentiment...\")\n",
        "        if not patient_text:\n",
        "            lines = [l.split(':', 1)[1].strip() for l in transcript.split('\\n')\n",
        "                    if 'patient:' in l.lower() and ':' in l]\n",
        "            patient_text = \" \".join(lines[:3])\n",
        "\n",
        "        sentiment = self.sentiment_analyzer.analyze(patient_text)\n",
        "\n",
        "        soap = self.soap_generator.generate(transcript)\n",
        "\n",
        "        print(\"\\n✓ PROCESSING COMPLETE\\n\")\n",
        "\n",
        "        return {\n",
        "            \"medical_summary\": asdict(summary),\n",
        "            \"sentiment_analysis\": asdict(sentiment),\n",
        "            \"soap_note\": asdict(soap)\n",
        "        }\n",
        "\n",
        "    def save_results(self, results: Dict, filename: str = \"clinical_results.json\"):\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"✅ Results saved to {filename}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    SAMPLE = \"\"\"\n",
        "Physician: Good morning, Ms. Jones. How are you feeling today?\n",
        "Patient: Good morning, doctor. I'm doing better, but I still have some discomfort now and then.\n",
        "Physician: I understand you were in a car accident last September. Can you walk me through what happened?\n",
        "Patient: Yes, it was on September 1st, around 12:30 in the afternoon. I was driving from Cheadle Hulme to Manchester when I had to stop in traffic. Out of nowhere, another car hit me from behind, which pushed my car into the one in front.\n",
        "Physician: That sounds like a strong impact. Were you wearing your seatbelt?\n",
        "Patient: Yes, I always do.\n",
        "Physician: What did you feel immediately after the accident?\n",
        "Patient: At first, I was just shocked. But then I realized I had hit my head on the steering wheel, and I could feel pain in my neck and back almost right away.\n",
        "Physician: Did you seek medical attention at that time?\n",
        "Patient: Yes, I went to Moss Bank Accident and Emergency. They checked me over and said it was a whiplash injury, but they didn't do any X-rays. They just gave me some advice and sent me home.\n",
        "Physician: How did things progress after that?\n",
        "Patient: The first four weeks were rough. My neck and back pain were really bad—I had trouble sleeping and had to take painkillers regularly. It started improving after that, but I had to go through ten sessions of physiotherapy to help with the stiffness and discomfort.\n",
        "Physician: That makes sense. Are you still experiencing pain now?\n",
        "Patient: It's not constant, but I do get occasional backaches. It's nothing like before, though.\n",
        "Physician: That's good to hear. Have you noticed any other effects, like anxiety while driving or difficulty concentrating?\n",
        "Patient: No, nothing like that. I don't feel nervous driving, and I haven't had any emotional issues from the accident.\n",
        "Physician: And how has this impacted your daily life? Work, hobbies, anything like that?\n",
        "Patient: I had to take a week off work, but after that, I was back to my usual routine. It hasn't really stopped me from doing anything.\n",
        "Physician: That's encouraging. Let's go ahead and do a physical examination to check your mobility and any lingering pain.\n",
        "[Physical Examination Conducted]\n",
        "Physician: Everything looks good. Your neck and back have a full range of movement, and there's no tenderness or signs of lasting damage. Your muscles and spine seem to be in good condition.\n",
        "Patient: That's a relief!\n",
        "Physician: Yes, your recovery so far has been quite positive. Given your progress, I'd expect you to make a full recovery within six months of the accident. There are no signs of long-term damage or degeneration.\n",
        "Patient: That's great to hear. So, I don't need to worry about this affecting me in the future?\n",
        "Physician: That's right. I don't foresee any long-term impact on your work or daily life. If anything changes or you experience worsening symptoms, you can always come back for a follow-up. But at this point, you're on track for a full recovery.\n",
        "Patient: Thank you, doctor. I appreciate it.\n",
        "Physician: You're very welcome, Ms. Jones. Take care, and don't hesitate to reach out if you need anything.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    pipeline = ClinicalTranscriptionPipeline(use_gpu=True)\n",
        "    results = pipeline.process_transcript(SAMPLE)\n",
        "\n",
        "\n",
        "\n",
        "    print(\" MEDICAL SUMMARY:\")\n",
        "    print(json.dumps(results['medical_summary'], indent=2))\n",
        "\n",
        "    print(\"\\n SENTIMENT ANALYSIS:\")\n",
        "    print(json.dumps(results['sentiment_analysis'], indent=2))\n",
        "\n",
        "    print(\"\\n SOAP NOTE:\")\n",
        "    print(json.dumps(results['soap_note'], indent=2))\n",
        "\n",
        "\n",
        "    print(\"✓ COMPLETE\")\n",
        "\n",
        "\n",
        "    pipeline.save_results(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
